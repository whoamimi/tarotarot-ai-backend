services:
  app:
    build:
      # https://www.docker.com/blog/llm-docker-for-local-and-hugging-face-hosting/
      dockerfile_inline: |
        FROM python:3.12-slim

        RUN useradd -m -u 1000 user
        RUN chsh -s /bin/bash user

        RUN apt-get update && apt-get install -y \
            curl \
            gcc \
            make \
            build-essential \
            ca-certificates \
            bash \
        && rm -rf /var/lib/apt/lists/*

        ENV PYTHONPATH=/code

        COPY /requirements.txt .
        RUN pip install --upgrade pip && pip install --no-cache-dir -r requirements.txt
        COPY /taro /code
        RUN chown -R user:user /code

        WORKDIR /code
        User user
    # CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8005", "--reload"]
    container_name: app
    entrypoint: ["/usr/bin/bash", "-c", "uvicorn app:app --host 0.0.0.0 --port 8005 --reload"]
    depends_on:
      - ollama
    env_file:
      - .env
    ports:
      - 8005:8005
    expose:
      - 8005
    environment:
      - PORT=8005
      - OLLAMA_BASE_URL=http://minis_ollama:11434
      - OLLAMA_HOST_URL=http://minis_ollama:11434
    networks:
      - minis-network
    volumes:
      - ollama-data:/code/ollama_root

  ollama:
    build:
      dockerfile_inline: |
        FROM ollama/ollama:latest
        WORKDIR /root
        COPY ./ollama_root /root
        RUN chmod +x /root/start_ollama.sh
    entrypoint: ["/usr/bin/bash", "./start_ollama.sh"]
    container_name: minis_ollama
    ports:
      - 11434:11434
    expose:
      - 11434
    volumes:
      - ./ollama_root:/root/.ollama
      - ollama-data:/root/.ollama
    pull_policy: always
    tty: true
    networks:
      - minis-network
    restart: unless-stopped

volumes:
  ollama-data:

networks:
  minis-network:
    driver: bridge